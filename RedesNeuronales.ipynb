{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe213dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/dana/.local/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /home/dana/.local/lib/python3.8/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/dana/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dana/.local/lib/python3.8/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: numpy in /home/dana/.local/lib/python3.8/site-packages (1.22.4)\n",
      "Requirement already satisfied: seaborn in /home/dana/.local/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/dana/.local/lib/python3.8/site-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/dana/.local/lib/python3.8/site-packages (from seaborn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/dana/.local/lib/python3.8/site-packages (from seaborn) (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/dana/.local/lib/python3.8/site-packages (from seaborn) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dana/.local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/dana/.local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (4.33.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib>=2.2->seaborn) (7.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/dana/.local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/dana/.local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dana/.local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/dana/.local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dana/.local/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.14.0)\n",
      "Requirement already satisfied: glob2 in /home/dana/.local/lib/python3.8/site-packages (0.7)\n",
      "Requirement already satisfied: opencv-python in /home/dana/.local/lib/python3.8/site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in /home/dana/.local/lib/python3.8/site-packages (from opencv-python) (1.22.4)\n",
      "Requirement already satisfied: tensorflow in /home/dana/.local/lib/python3.8/site-packages (2.9.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (1.22.4)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: packaging in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (1.46.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/dana/.local/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/dana/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/dana/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/dana/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/dana/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/dana/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/dana/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/dana/.local/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/dana/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/dana/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.11.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/dana/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dana/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/dana/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/dana/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/dana/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/dana/.local/lib/python3.8/site-packages (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/dana/.local/lib/python3.8/site-packages (from matplotlib) (1.22.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dana/.local/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/dana/.local/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/dana/.local/lib/python3.8/site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/dana/.local/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dana/.local/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (7.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/dana/.local/lib/python3.8/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install seaborn\n",
    "!pip install glob2\n",
    "!pip install opencv-python\n",
    "!pip install tensorflow\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54f2e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 19:39:59.572826: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-01 19:39:59.618617: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dana/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-06-01 19:39:59.618632: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a299b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94bc4fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.22.4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da6acda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac9a0736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a11e3832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dana/redes-neuronales/chest_xray\n"
     ]
    }
   ],
   "source": [
    "current_directory = !pwd\n",
    "path = current_directory[0] + '/chest_xray'\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "595e52ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (7.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f74db2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la cantidad de pneumonia 3875\n"
     ]
    }
   ],
   "source": [
    "pneumonia_train = []\n",
    "for img_path in glob.glob(path + '/train/PNEUMONIA/*'):\n",
    "  image = Image.open(img_path)\n",
    "  image.thumbnail((400, 400))\n",
    "  image.save(img_path)\n",
    "  pneumonia_train.append(mpimg.imread(img_path))\n",
    "\n",
    "print(\"la cantidad de pneumonia\", len(pneumonia_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "739bc6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la cantidad de sanos 1341\n"
     ]
    }
   ],
   "source": [
    "normal_train = []\n",
    "for img_path in glob.glob(path + '/train/NORMAL/*'):\n",
    "  normal_train.append(mpimg.imread(img_path))\n",
    "\n",
    "print(\"la cantidad de sanos\", len(normal_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c678081",
   "metadata": {},
   "source": [
    "data = pd.DataFrame(np.concatenate([[0]*len(normal_train) , [1]*len(pneumonia_train)]),columns=[\"class\"])\n",
    "\n",
    "data.head()\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.countplot(data['class'],data=data,palette='rocket')\n",
    "plt.title('PNEUMONIA vs NORMAL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ad16f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01d9e2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = current_directory[0] + \"/chest_xray/train\"\n",
    "test_dir = current_directory[0] + \"/chest_xray/test\"\n",
    "val_dir = current_directory[0] + \"/chest_xray/val\"\n",
    "\n",
    "img_Datagen = ImageDataGenerator(\n",
    "        rescale = 1/255,\n",
    "        shear_range=10,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        brightness_range=[0.5,2.0],\n",
    "        width_shift_range = 0.2,\n",
    "        rotation_range=20,\n",
    "        fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "val_Datagen = ImageDataGenerator(\n",
    "        rescale = 1/255\n",
    ")\n",
    "\n",
    "train = img_Datagen.flow_from_directory(train_dir,\n",
    "                                       batch_size=32,\n",
    "                                       class_mode='binary',\n",
    "#                                        target_size=(224,224,3))\n",
    "                                       )\n",
    "\n",
    "validation = val_Datagen.flow_from_directory(val_dir,\n",
    "                                              batch_size=2,\n",
    "                                              class_mode='binary',\n",
    "#                                               target_size=(224,224,3))\n",
    "                                            )\n",
    "\n",
    "test = val_Datagen.flow_from_directory(test_dir,\n",
    "                                       batch_size=2,\n",
    "                                       class_mode='binary',\n",
    "#                                        target_size=(224/,224,3))\n",
    "                                      )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef30e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### V G G 1 9 ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad058154",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = tf.keras.applications.VGG19(\n",
    "    weights='imagenet',\n",
    "    include_top = False,\n",
    "#     input_shape = (224,224,3)\n",
    ")\n",
    "\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "x = vgg_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "\n",
    "# output layer\n",
    "predictions = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=vgg_model.input, outputs=predictions)\n",
    "\n",
    "# to avoid overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10)\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=8)\n",
    "\n",
    "# Compiling the model\n",
    "\n",
    "# lo que nosotros entendemos es que el parametro que paso es para specificity\n",
    "# Como sensitivity es true positives y specificity son true negatives\n",
    "# nos parecio mas importante tener un sentitivity alto, dado que \"te dijimos que no tenias neumonia\" y si tenias, es el peor caso\n",
    "# por eso decidimos utilizar SensitivityAtSpecificity(0.5) con 0.5, dado que \n",
    "# un true negative en la mitad de los casos no es tan malo.\n",
    "#es preferible acertarble en la mayoria de los casos true positives \n",
    "\n",
    "#PREGUNTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAR PORQUE NO ENTIENDO NAAAAAAAAAAAAAAAAAAAAAAAAAAAAAH\n",
    "\n",
    "model.compile(loss='mse', optimizer='sgd',metrics=[tf.keras.metrics.SensitivityAtSpecificity(0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec8f6616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " global_average_pooling2d_5   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,090,177\n",
      "Trainable params: 65,793\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b103aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 502s 5s/step - loss: 0.1883 - sensitivity_at_specificity_1: 0.4649 - val_loss: 0.3094 - val_sensitivity_at_specificity_1: 0.5000 - lr: 0.0100\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 504s 5s/step - loss: 0.1892 - sensitivity_at_specificity_1: 0.6150 - val_loss: 0.2952 - val_sensitivity_at_specificity_1: 0.8750 - lr: 0.0100\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 493s 5s/step - loss: 0.1843 - sensitivity_at_specificity_1: 0.7449 - val_loss: 0.3024 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 511s 5s/step - loss: 0.1816 - sensitivity_at_specificity_1: 0.7715 - val_loss: 0.2968 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 485s 5s/step - loss: 0.1787 - sensitivity_at_specificity_1: 0.8212 - val_loss: 0.2941 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 454s 5s/step - loss: 0.1748 - sensitivity_at_specificity_1: 0.8406 - val_loss: 0.2672 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 459s 5s/step - loss: 0.1745 - sensitivity_at_specificity_1: 0.8430 - val_loss: 0.2737 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 450s 4s/step - loss: 0.1688 - sensitivity_at_specificity_1: 0.8551 - val_loss: 0.2781 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 453s 5s/step - loss: 0.1665 - sensitivity_at_specificity_1: 0.8586 - val_loss: 0.2772 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 449s 4s/step - loss: 0.1700 - sensitivity_at_specificity_1: 0.8519 - val_loss: 0.2496 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 447s 4s/step - loss: 0.1652 - sensitivity_at_specificity_1: 0.8721 - val_loss: 0.2578 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 452s 5s/step - loss: 0.1667 - sensitivity_at_specificity_1: 0.8780 - val_loss: 0.2527 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 451s 5s/step - loss: 0.1635 - sensitivity_at_specificity_1: 0.8654 - val_loss: 0.2819 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 441s 4s/step - loss: 0.1639 - sensitivity_at_specificity_1: 0.8549 - val_loss: 0.2452 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 440s 4s/step - loss: 0.1604 - sensitivity_at_specificity_1: 0.8855 - val_loss: 0.2157 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 438s 4s/step - loss: 0.1595 - sensitivity_at_specificity_1: 0.8682 - val_loss: 0.2651 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 439s 4s/step - loss: 0.1614 - sensitivity_at_specificity_1: 0.8645 - val_loss: 0.2237 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 438s 4s/step - loss: 0.1591 - sensitivity_at_specificity_1: 0.8949 - val_loss: 0.2214 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 437s 4s/step - loss: 0.1570 - sensitivity_at_specificity_1: 0.8768 - val_loss: 0.2415 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 435s 4s/step - loss: 0.1535 - sensitivity_at_specificity_1: 0.8885 - val_loss: 0.2195 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 436s 4s/step - loss: 0.1546 - sensitivity_at_specificity_1: 0.8912 - val_loss: 0.2272 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 436s 4s/step - loss: 0.1511 - sensitivity_at_specificity_1: 0.8871 - val_loss: 0.2440 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 434s 4s/step - loss: 0.1541 - sensitivity_at_specificity_1: 0.8712 - val_loss: 0.2141 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 434s 4s/step - loss: 0.1518 - sensitivity_at_specificity_1: 0.8914 - val_loss: 0.2072 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 433s 4s/step - loss: 0.1543 - sensitivity_at_specificity_1: 0.8764 - val_loss: 0.2207 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 433s 4s/step - loss: 0.1510 - sensitivity_at_specificity_1: 0.8853 - val_loss: 0.2130 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 433s 4s/step - loss: 0.1481 - sensitivity_at_specificity_1: 0.8938 - val_loss: 0.2136 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 432s 4s/step - loss: 0.1483 - sensitivity_at_specificity_1: 0.8825 - val_loss: 0.2216 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 432s 4s/step - loss: 0.1498 - sensitivity_at_specificity_1: 0.8883 - val_loss: 0.2184 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 433s 4s/step - loss: 0.1444 - sensitivity_at_specificity_1: 0.8999 - val_loss: 0.1959 - val_sensitivity_at_specificity_1: 1.0000 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train,epochs=30, \n",
    "                    validation_data=validation,\n",
    "                     steps_per_epoch=100,\n",
    "                    callbacks=[early_stopping,lr],\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02961662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on train and test\n",
    "score = model.evaluate(train)\n",
    "print(score)\n",
    "\n",
    "print(\"Train Loss: \", score[0])\n",
    "print(\"Train Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c73bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "score = model.evaluate(test)\n",
    "\n",
    "print(\"Test Loss: \", score[0])\n",
    "print(\"Test Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('EVALUATION OF VGG19')\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val_Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Evolution')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val_Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy Evolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc513d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### X C E P T I O N ###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f51a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "INVESTIGAR QUE PORONGA HACE CADA PARAMETRO\n",
    "tf.keras.applications.xception.Xception(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "'''\n",
    "\n",
    "xception_model = tf.keras.applications.Xception(\n",
    "    weights='imagenet',\n",
    "    include_top = False,\n",
    "#     input_shape = (224,224,3)\n",
    ")\n",
    "\n",
    "for layer in xception_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "x = xception_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "\n",
    "# output layer\n",
    "predictions = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=xception_model.input, outputs=predictions)\n",
    "\n",
    "# to avoid overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10)\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=8)\n",
    "\n",
    "# Compiling the model\n",
    "#PREGUNTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAR PORQUE NO ENTIENDO NAAAAAAAAAAAAAAAAAAAAAAAAAAAAAH\n",
    "\n",
    "#QUE DIFERENCIA TIENE LA REGRESION ACA? NO ENTIENDO\n",
    "\n",
    "#model.compile(loss='binary_crossentropy', optimizer='sgd',metrics=[tf.keras.metrics.SensitivityAtSpecificity(0.5)])\n",
    "model.compile(loss='mse', optimizer='sgd',metrics=[tf.keras.metrics.SensitivityAtSpecificity(0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f5ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### I N C E P T I O N   V 3  ###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc24a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "inceptionv3_model = tf.keras.applications.InceptionV3(\n",
    "    weights='imagenet',\n",
    "    include_top = False,\n",
    "#     input_shape = (224,224,3)\n",
    ")\n",
    "\n",
    "for layer in inceptionv3_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "x = inceptionv3_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "\n",
    "# output layer\n",
    "predictions = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inceptionv3_model.input, outputs=predictions)\n",
    "\n",
    "# to avoid overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10)\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=8)\n",
    "\n",
    "# Compiling the model\n",
    "#PREGUNTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAR PORQUE NO ENTIENDO NAAAAAAAAAAAAAAAAAAAAAAAAAAAAAH\n",
    "\n",
    "#QUE DIFERENCIA TIENE LA REGRESION ACA? NO ENTIENDO\n",
    "\n",
    "#model.compile(loss='binary_crossentropy', optimizer='sgd',metrics=[tf.keras.metrics.SensitivityAtSpecificity(0.5)])\n",
    "model.compile(loss='mse', optimizer='sgd',metrics=[tf.keras.metrics.SensitivityAtSpecificity(0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c467c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### R E S N E T   50  ###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b3c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "resnet50_model = tf.keras.applications.ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top = False,\n",
    "#     input_shape = (224,224,3)\n",
    ")\n",
    "\n",
    "for layer in resnet50_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "x = resnet50_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "\n",
    "# output layer\n",
    "predictions = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=resnet50_model.input, outputs=predictions)\n",
    "\n",
    "# to avoid overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10)\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=8)\n",
    "\n",
    "# Compiling the model\n",
    "#PREGUNTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAR PORQUE NO ENTIENDO NAAAAAAAAAAAAAAAAAAAAAAAAAAAAAH\n",
    "\n",
    "#QUE DIFERENCIA TIENE LA REGRESION ACA? NO ENTIENDO\n",
    "\n",
    "#model.compile(loss='binary_crossentropy', optimizer='sgd',metrics=[tf.keras.metrics.SensitivityAtSpecificity(0.5)])\n",
    "model.compile(loss='mse', optimizer='sgd',metrics=[tf.keras.metrics.SensitivityAtSpecificity(0.5)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
